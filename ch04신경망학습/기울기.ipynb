{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num = 100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)\n",
    "\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "lr = 0.1\n",
    "step_num = 20\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "\n",
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48564156  0.0093021  -0.49494366]\n",
      " [ 0.72846234  0.01395316 -0.74241549]]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "t = np.array([0, 0, 1])\n",
    "\n",
    "net = simpleNet()\n",
    "\n",
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
